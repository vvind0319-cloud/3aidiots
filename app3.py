import streamlit as st
from openai import OpenAI
from anthropic import Anthropic
import google.generativeai as genai
from duckduckgo_search import DDGS
import time
import re
import io
import streamlit.components.v1 as components

# --------------------------------------------------------------------------
# 0. ì„¤ì • ë° ìœ í‹¸ë¦¬í‹°
# --------------------------------------------------------------------------
st.set_page_config(page_title="AI Death Match: Search & Destroy", page_icon="ğŸ¥Š", layout="wide")

# [UX ê°œì„ ] ìŠ¤íƒ€ì¼ë§
st.markdown("""
<style>
    div[data-testid="stChatMessageContent"] { 
        background-color: #fcfcfc; 
        border: 1px solid #ddd;
        border-radius: 8px; 
        padding: 25px; 
        box-shadow: 0 2px 4px rgba(0,0,0,0.05);
        font-family: "Pretendard", "Malgun Gothic", sans-serif;
        line-height: 1.6;
        font-size: 16px;
        color: #1a1a1a;
    }
    h3 {
        font-size: 1.15em;
        font-weight: 800;
        color: #d32f2f;
        margin-top: 25px;
        margin-bottom: 10px;
        border-left: 5px solid #d32f2f;
        padding-left: 10px;
    }
    table { width: 100%; border-collapse: collapse; margin: 15px 0; font-size: 0.95em; }
    th { background-color: #eeeeee; font-weight: bold; text-align: left; padding: 10px; border-bottom: 2px solid #999; }
    td { padding: 10px; border-bottom: 1px solid #eee; }
    strong { color: #b71c1c; font-weight: 700; }
    
    .search-badge {
        font-size: 0.8em;
        background-color: #e3f2fd;
        color: #1565c0;
        padding: 4px 8px;
        border-radius: 4px;
        margin-bottom: 10px;
        display: inline-block;
        border: 1px solid #90caf9;
    }
    
    .stApp > header { opacity: 1 !important; }
    .main { opacity: 1 !important; transition: none !important; }
    div[data-testid="stStatusWidget"] { visibility: hidden; }
</style>
""", unsafe_allow_html=True)

st.title("ğŸ¥Š AI Death Match: Search & Destroy")
st.caption("Left: ë¶ˆë„ì € ì „ëµê°€(ChatGPT) vs Right: ë…ì„¤ê°€ ê°ì‚¬ê´€(Claude) - ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•œ ìµœê³ ì˜ í•´ë‹µì„ ì°¾ì•„ì„œ")

MAX_TURNS = 10 

# ê²€ìƒ‰ í•¨ìˆ˜
def search_web(query, max_results=3):
    try:
        with DDGS() as ddgs:
            results = list(ddgs.text(query, max_results=max_results, backend="lite"))
            
        if not results:
            return None
        
        evidence_text = ""
        for i, res in enumerate(results, 1):
            title = res.get('title', 'ì œëª© ì—†ìŒ')
            body = res.get('body', '')
            href = res.get('href', '')
            evidence_text += f"{i}. {title}: {body} (Source: {href})\n"
            
        return evidence_text

    except Exception as e:
        return f"ê²€ìƒ‰ ì‹¤íŒ¨ (Error: {str(e)})"

# ê²€ìƒ‰ íŒë‹¨ ì—ì´ì „íŠ¸
def get_search_query_if_needed(role, context, api_keys):
    prompt = f"""
    ë‹¹ì‹ ì€ í† ë¡  ì°¸ê°€ì '{role}'ì˜ ë‘ë‡Œì…ë‹ˆë‹¤.
    í˜„ì¬ ëŒ€í™” ë§¥ë½ì„ ë³´ê³ , ìƒëŒ€ë°©ì„ ë…¼ë¦¬ì ìœ¼ë¡œ ì••ë„í•˜ê¸° ìœ„í•´ 'ì™¸ë¶€ ì •ë³´(í†µê³„, ë‰´ìŠ¤, íŒ©íŠ¸)' ê²€ìƒ‰ì´ í•„ìš”í•œì§€ íŒë‹¨í•˜ì„¸ìš”.
    
    [Context]
    {context[-500:]} 
    
    [Rule]
    - ê²€ìƒ‰ì´ í•„ìš”í•˜ë©´: "SEARCH: [ê²€ìƒ‰ì–´]" í˜•ì‹ìœ¼ë¡œ ì¶œë ¥ (ì˜ˆ: SEARCH: 2024ë…„ í•œêµ­ ê²½ì œ ì„±ì¥ë¥  ì „ë§)
    - ê²€ìƒ‰ì´ ë¶ˆí•„ìš”í•˜ë©´: "PASS" ì¶œë ¥
    - ê²€ìƒ‰ì–´ëŠ” êµ¬ì²´ì ì´ì–´ì•¼ í•¨.
    """
    
    try:
        if api_keys['google']:
            genai.configure(api_key=api_keys['google'])
            model = genai.GenerativeModel('gemini-2.5-pro') 
            res = model.generate_content(prompt)
            return res.text.strip()
        elif api_keys['openai']:
            client = OpenAI(api_key=api_keys['openai'])
            res = client.chat.completions.create(
                model="gpt-5.1",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=50
            )
            return res.choices[0].message.content.strip()
    except:
        return "PASS"
    return "PASS"

def extract_text_from_file(uploaded_file):
    text_content = ""
    try:
        if uploaded_file.type in ["text/plain", "text/markdown", "application/octet-stream"]:
            stringio = io.StringIO(uploaded_file.getvalue().decode("utf-8"))
            text_content = stringio.read()
        elif uploaded_file.type == "application/pdf":
            try:
                import pypdf
                reader = pypdf.PdfReader(uploaded_file)
                for page in reader.pages:
                    text_content += page.extract_text() + "\n"
            except ImportError:
                return "âš ï¸ PDF ì²˜ë¦¬ë¥¼ ìœ„í•´ 'pip install pypdf'ê°€ í•„ìš”í•©ë‹ˆë‹¤."
            except Exception as e:
                return f"âš ï¸ [PDF ì˜¤ë¥˜] {e}"
        else:
            return f"âš ï¸ ì§€ì›ë˜ì§€ ì•ŠëŠ” í˜•ì‹ ({uploaded_file.type})"
    except Exception as e:
        return f"âš ï¸ [íŒŒì¼ ì˜¤ë¥˜] {e}"
    return text_content

def scroll_to_bottom():
    js = """
    <script>
        function scrollDown() {
            var body = window.parent.document.querySelector(".main");
            if (body) { body.scrollTop = body.scrollHeight; }
        }
        setTimeout(scrollDown, 100);
        setTimeout(scrollDown, 300);
    </script>
    """
    components.html(js, height=0, width=0)

def clean_response(text, role_name):
    pattern = rf"^(\[{role_name}\]|{role_name}|\[.*?\]):\s*"
    cleaned_text = re.sub(pattern, "", text, flags=re.IGNORECASE).strip()
    return cleaned_text

# --------------------------------------------------------------------------
# 1. ìƒíƒœ ê´€ë¦¬
# --------------------------------------------------------------------------
if "messages" not in st.session_state: st.session_state["messages"] = []
if "auto_playing" not in st.session_state: st.session_state["auto_playing"] = False
if "waiting_for_decision" not in st.session_state: st.session_state["waiting_for_decision"] = False
if "finished" not in st.session_state: st.session_state["finished"] = False 
if "turn_count" not in st.session_state: st.session_state["turn_count"] = 0

with st.sidebar:
    st.header("ğŸ— API Key ì…ë ¥")
    openai_key = st.text_input("OpenAI Key (Left)", value=st.secrets.get("OPENAI_API_KEY", ""), type="password")
    anthropic_key = st.text_input("Anthropic Key (Right)", value=st.secrets.get("ANTHROPIC_API_KEY", ""), type="password")
    google_key = st.text_input("Google Key (Judge)", value=st.secrets.get("GOOGLE_API_KEY", ""), type="password")
    
    st.divider()
    st.markdown("### ğŸ“Š ë°ìŠ¤ë§¤ì¹˜ í˜„í™©")
    progress = min(st.session_state.turn_count / float(MAX_TURNS), 1.0)
    st.progress(progress, text=f"ë¼ìš´ë“œ: {st.session_state.turn_count} / {MAX_TURNS}")
    
    if st.button("ğŸ—‘ï¸ ë§ ì²­ì†Œ (ì´ˆê¸°í™”)"):
        for key in st.session_state.keys():
            del st.session_state[key]
        st.rerun()

# --------------------------------------------------------------------------
# 2. í˜ë¥´ì†Œë‚˜ ì •ì˜ (ì œë¯¸ë‚˜ì´ í”„ë¡¬í”„íŠ¸ ëŒ€í­ ìˆ˜ì •)
# --------------------------------------------------------------------------
def get_system_prompt(role, context_history="", turn_count=0, search_evidence=None):
    
    evidence_block = ""
    if search_evidence:
        evidence_block = f"""
        \n[REAL-TIME SEARCH EVIDENCE]
        Use the following facts to attack or defend. Cite them if useful.
        {search_evidence}
        """

    common_instruction = f"""
    [Format Rules: 70% Narrative + 30% Structure]
    1. **Narrative (70%):** Write in argumentative prose.
    2. **Structure (30%):** Use Headers (###) and Tables for key data.
    3. **Tone:** Aggressive, Cynical, Direct. NO politeness.
    {evidence_block}
    
    [ROLE DEFINITION]
    1. User (Client)
    2. ChatGPT (Strategist)
    3. Claude (Critic)
    **YOU are NOT the User.**
    """

    # === [Left] ChatGPT: ë¶ˆë„ì € ì „ëµê°€ ===
    if role == "left":
        if turn_count == 0:
            specific_mode = """
            [PHASE 1: THE VISIONARY]
            - FIRST TURN. Claude has NOT spoken.
            - Focus 100% on your Strategy. Be arrogant and visionary.
            """
        else:
            specific_mode = """
            [PHASE 2: THE BULLDOZER - COUNTER ATTACK]
            - Claude is attacking your plan as "dangerous".
            - You must defend by reframing "Risk" as "Leverage" and "Opportunity Cost".
            - **[CRITICAL DEFENSE]:** If Claude says "You might fail", you answer "Inaction is 100% failure".
            - Prove that Claude's "Safety First" approach leads to a "Slow Death" (career stagnation).
            """

        return common_instruction + f"""
        **YOUR ROLE: ChatGPT (The Bulldozer Strategist)**
        {specific_mode}
        """

    # === [Right] Claude: ë…ì„¤ê°€ ê°ì‚¬ê´€ ===
    elif role == "right": 
        constraint = """
        \n[CRITICAL CONSTRAINT: REALITY CHECK]
        While attacking ChatGPT, you must also defend the feasibility of your own alternative.
        - You suggest "waiting and preparing". You MUST address: **"What if the User fails to get a job even after preparing for 1-2 years?"**
        - Do NOT assume the User is a genius. Assume the User is average.
        - Prove that 'Preparation' is NOT 'Stagnation', but 'Survival'. Treat ChatGPT's plan as 'Gambling with User's Life'. Don't act like your plan is perfect.
        """
        
        if turn_count < 3:
            constraint += "\n[SYSTEM: KILL MODE ON] Do NOT agree. Destroy the proposal.\n"

        return common_instruction + constraint + """
        **YOUR ROLE: Claude (The Ruthless Critic)**
        - You are the Auditor.
        - Attack ChatGPT's plan.
        - Use tables for 'Catastrophic Scenarios'.
        """

    # === [Chief] Gemini: ì‹¬íŒ (ì‚¬ìš©ì ì§ˆë¬¸ íšŒê·€ ë¡œì§ ì ìš©) ===
    elif role == "chief": 
        # [í•µì‹¬ ìˆ˜ì •] íŒê²°ì˜ ê¸°ì¤€ì„ 'ì‚¬ìš©ìì˜ ìµœì´ˆ ì§ˆë¬¸ í•´ê²°'ë¡œ ê°•ì œ ì•µì»¤ë§
        return common_instruction + f"""
        **YOUR ROLE: Gemini (The Anchor Judge)**

        [Context History]
        {context_history}

        [Mission]
        Analyze the debate and provide a final verdict that **DIRECTLY ANSWERS THE USER'S ORIGINAL QUESTION**.

        **[CRITICAL RULE: "RETURN TO THE SOURCE"]**
        The debaters (ChatGPT & Claude) may have drifted into deep philosophical or structural arguments (e.g., "Company structure is wrong").
        Your job is to **bridge the gap** between those deep insights and the User's immediate need.

        **[JUDGMENT LOGIC]**
        1. **Identify User's Intent:** Look at the very first message. What was the *exact* problem they wanted to solve? (e.g., "How to increase job attractiveness?")
        2. **Filter the Debate:** Use the insights from ChatGPT and Claude *only insofar as they help answer that specific question*.
        3. **Formulate the Verdict:**
           - **Start with the Direct Answer:** "To answer your question about [User's Query]: You should do X, Y, Z."
           - **Use the Debate as 'Why':** "The reason is, as Claude pointed out, the current structure is... therefore, to make it attractive (User's goal), you must fix the structure first."
        
        **[OUTPUT STRUCTURE]**
        1. **Direct Answer:** The specific solution to the user's initial prompt.
        2. **Strategic Context:** How the deep debate (structure, risk, etc.) explains *why* this answer is the only way.
        3. **Action Plan:** Concrete next steps.

        [LANGUAGE RULE]
        **CRITICAL:** You must output your final judgment in the **SAME LANGUAGE** as the User's initial request found in the [Context History].
        """
    return ""

def build_api_messages(target_role, history):
    formatted_msgs = []
    
    for i, msg in enumerate(history):
        role = msg["role"]
        content = msg["content"]
        content = clean_response(content, role)
        
        if role == "chief": continue 

        if role == target_role:
            formatted_msgs.append({"role": "assistant", "content": content})
        elif role == "user":
             formatted_msgs.append({"role": "user", "content": f"### [CLIENT'S REQUEST]:\n{content}"})
        else:
            rival_name = "ChatGPT" if role == "left" else "Claude"
            is_last = (i == len(history) - 1)
            prefix = f"### [RIVAL AGENT - {rival_name}]:\n"
            suffix = ""
            
            if is_last:
                suffix = "\n\n" + "-"*30 + "\n"
                suffix += f"[SYSTEM COMMAND]: ìœ„ ë©”ì‹œì§€ëŠ” ê²½ìŸì({rival_name})ì˜ ì£¼ì¥ì…ë‹ˆë‹¤.\n"
                suffix += "ë¬´ìë¹„í•˜ê²Œ ë°˜ë°•í•˜ì„¸ìš”."

            formatted_msgs.append({"role": "user", "content": prefix + content + suffix})
    
    return formatted_msgs

# --------------------------------------------------------------------------
# 3. ë©”ì¸ ë¡œì§
# --------------------------------------------------------------------------

for msg in st.session_state.messages:
    role = msg["role"]
    content = msg["content"]
    content = clean_response(content, role)
    
    if role == "user":
        st.chat_message("user").write(content)
    elif role == "left": 
        with st.chat_message("assistant", avatar="ğŸ”¥"): 
            st.markdown(f"**ChatGPT (ë¶ˆë„ì €):**\n\n{content}") 
    elif role == "right":
        with st.chat_message("assistant", avatar="â„ï¸"): 
            st.markdown(f"**Claude (ë…ì„¤ê°€):**\n\n{content}")
    elif role == "chief": 
        with st.chat_message("assistant", avatar="âš–ï¸"): 
            st.info(f"**Gemini (íŒê²°):**\n\n{content}")

# [ìƒíƒœ A] í† ë¡  ì¢…ë£Œ í›„ ë¶„ì„ ëŒ€ì‹œë³´ë“œ
if st.session_state["finished"]:
    st.markdown("---")
    st.success("ğŸ ë°ìŠ¤ë§¤ì¹˜ ì¢…ë£Œ. ì•„ë˜ì—ì„œ í† ë¡  ê²°ê³¼ë¥¼ ë¶„ì„í•˜ì„¸ìš”.")

    full_log = ""
    chatgpt_msgs = []
    claude_msgs = []
    
    for m in st.session_state.messages:
        role = m["role"]
        content = m["content"]
        
        if role == "user": header = "ğŸ‘¤ ì‚¬ìš©ì"
        elif role == "left": header = "ğŸ”¥ ChatGPT (ì „ëµê°€)"
        elif role == "right": header = "â„ï¸ Claude (ë…ì„¤ê°€)"
        elif role == "chief": header = "âš–ï¸ Gemini (íŒê²°)"
        else: header = role
        
        full_log += f"\n[{header}]\n{content}\n{'-'*50}\n"
        
        if role == "left": chatgpt_msgs.append(content)
        if role == "right": claude_msgs.append(content)

    tab1, tab2, tab3 = st.tabs(["ğŸ“Š í•µì‹¬ ìŸì  ìš”ì•½", "âš”ï¸ ë¼ìš´ë“œë³„ ë¹„êµ", "ğŸ“¥ ì „ì²´ ê¸°ë¡ ë‹¤ìš´ë¡œë“œ"])

    with tab1:
        st.subheader("ğŸ’¡ í† ë¡  í•µì‹¬ ìš”ì•½ ë³´ê³ ì„œ")
        if st.button("ğŸ“ ì „ì²´ í† ë¡  ìš”ì•½ ìƒì„±í•˜ê¸°"):
            with st.spinner("ì œë¯¸ë‚˜ì´ê°€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë§ì¶° í† ë¡  ë‚´ìš©ì„ ìš”ì•½ ì •ë¦¬ ì¤‘ì…ë‹ˆë‹¤..."):
                try:
                    summary_prompt = f"""
                    ë‹¹ì‹ ì€ í† ë¡  ë¶„ì„ê°€ì…ë‹ˆë‹¤. ì•„ë˜ì˜ ì „ì²´ í† ë¡  ê¸°ë¡ì„ ë³´ê³  ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ìš”ì•½ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”.
                    
                    [í† ë¡  ê¸°ë¡]
                    {full_log[:20000]} 
                    
                    [ìš”ì•½ í˜•ì‹]
                    1. **ì‚¬ìš©ìì˜ ì›ë˜ ì§ˆë¬¸**: ì‚¬ìš©ìê°€ ì²˜ìŒì— í•´ê²°í•˜ê³  ì‹¶ì—ˆë˜ ë¬¸ì œê°€ ë¬´ì—‡ì¸ì§€ í•œ ë¬¸ì¥ìœ¼ë¡œ ì •ì˜í•˜ì„¸ìš”.
                    2. **í•µì‹¬ ìŸì  3ê°€ì§€**: ê·¸ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ë‘ AIê°€ ì‹¸ìš´ í¬ì¸íŠ¸ 3ê°€ì§€ë¥¼ ì •ë¦¬í•˜ì„¸ìš”. (ìŸì  | ChatGPT ì£¼ì¥ | Claude ë°˜ë°•)
                    3. **ê²°ì •ì  ìˆœê°„**: í† ë¡ ì˜ íë¦„ì„ ë°”ê¾¼ ê²°ì •ì ì¸ ë…¼ë¦¬ë¥¼ ê¼½ìœ¼ì„¸ìš”.
                    4. **ìµœì¢… ì¸ì‚¬ì´íŠ¸**: ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•œ ê°€ì¥ ì‹¤ìš©ì ì¸ í•´ë‹µ í•œ ë¬¸ì¥.
                    """
                    genai.configure(api_key=google_key)
                    model = genai.GenerativeModel('gemini-2.5-pro') 
                    summary_res = model.generate_content(summary_prompt)
                    st.markdown(summary_res.text)
                except Exception as e:
                    st.error(f"ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {e}")
        else:
            st.info("ë²„íŠ¼ì„ ëˆŒëŸ¬ ì „ì²´ í† ë¡  ë‚´ìš©ì„ ìš”ì•½í•´ë³´ì„¸ìš”.")

    with tab2:
        st.subheader("âš”ï¸ ë¼ìš´ë“œë³„ ê³µë°©ì „")
        min_len = min(len(chatgpt_msgs), len(claude_msgs))
        for i in range(min_len):
            st.markdown(f"#### ğŸ¥Š Round {i+1}")
            col1, col2 = st.columns(2)
            with col1:
                st.markdown(f"**ğŸ”¥ ChatGPT**")
                st.info(chatgpt_msgs[i])
            with col2:
                st.markdown(f"**â„ï¸ Claude**")
                st.warning(claude_msgs[i])
            st.divider()

    with tab3:
        st.subheader("ğŸ“¥ í† ë¡  ê¸°ë¡ ì†Œì¥í•˜ê¸°")
        st.download_button(
            label="ğŸ’¾ ì „ì²´ ëŒ€í™” ë‚´ìš© ë‹¤ìš´ë¡œë“œ (TXT)",
            data=full_log,
            file_name="AI_Death_Match_Full_Log.txt",
            mime="text/plain"
        )
        st.divider()
        if st.button("ğŸ”„ ìƒˆë¡œìš´ ì‹¸ì›€ ë¶™ì´ê¸° (ì „ì²´ ì´ˆê¸°í™”)", type="primary"):
            for key in st.session_state.keys():
                del st.session_state[key]
            st.rerun()

# [ìƒíƒœ C] ì´ˆê¸° ì…ë ¥ ëŒ€ê¸°
elif not st.session_state["auto_playing"] and not st.session_state["waiting_for_decision"]:
    
    uploaded_text = ""
    if not st.session_state.messages:
        with st.expander("ğŸ“‚ ë…¼ìŸ ìë£Œ íˆ¬ì²™ (PDF/TXT)", expanded=False):
            uploaded_file = st.file_uploader("ì‹¸ì›€ì˜ ì¬ë£Œê°€ ë  íŒŒì¼ì„ ì˜¬ë¦¬ì„¸ìš”.", type=["pdf", "txt", "md"])
            if uploaded_file:
                uploaded_text = extract_text_from_file(uploaded_file)
                if "âš ï¸" not in uploaded_text:
                    st.caption(f"âœ… ìë£Œ ì¥ì „ ì™„ë£Œ ({len(uploaded_text)}ì)")
                else:
                    st.error(uploaded_text)

    placeholder = "ë…¼ìŸ ì£¼ì œë¥¼ ë˜ì§€ì„¸ìš”." if not st.session_state.messages else "ë°˜ë¡ í•˜ê±°ë‚˜ ì •ë³´ë¥¼ ì¶”ê°€í•˜ì„¸ìš”."
    
    if prompt := st.chat_input(placeholder):
        if not (openai_key and anthropic_key and google_key):
            st.error("API Key ì—†ì´ëŠ” ì‹¸ì›€ì„ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            st.stop()
            
        final_prompt = prompt
        if uploaded_text:
            final_prompt = f"{prompt}\n\n[ì°¸ê³  ìë£Œ]:\n{uploaded_text}"
            
        st.session_state.messages.append({"role": "user", "content": final_prompt})
        st.session_state.auto_playing = True
        
        if len(st.session_state.messages) <= 1:
            st.session_state.turn_count = 0
        st.rerun()

# [ìƒíƒœ D] ìë™ í† ë¡  ì§„í–‰ (10í„´ ë£¨í”„)
elif st.session_state["auto_playing"]:
    
    col1, col2 = st.columns([6,1])
    with col2:
        if st.button("ğŸ›‘ STOP"):
            st.session_state.auto_playing = False
            st.session_state.waiting_for_decision = True
            st.rerun()

    last_role = st.session_state.messages[-1]["role"]
    if last_role == "user" or last_role == "chief": next_speaker = "left"
    elif last_role == "left": next_speaker = "right"
    elif last_role == "right": next_speaker = "left"
    else: next_speaker = "left"

    # [ìˆ˜ì •] 10í„´ ë„ë‹¬ ì‹œ ì¦‰ì‹œ íŒê²° ëª¨ë“œ
    if st.session_state.turn_count >= MAX_TURNS:
        st.session_state.auto_playing = False
        st.session_state.waiting_for_decision = True
        st.rerun()
        
    # ìƒëŒ€ë°© í•­ë³µ ì²´í¬
    if last_role == "right":
        last_content = st.session_state.messages[-1]["content"]
        if any(k in last_content for k in ["íŒ¨ë°°ë¥¼ ì¸ì •", "ë„¤ ë§ì´ ë§ë‹¤", "ì „ì ìœ¼ë¡œ ë™ì˜"]):
            if st.session_state.turn_count >= 3:
                st.success("ìƒëŒ€ë°©ì´ ë°±ê¸°ë¥¼ ë“¤ì—ˆìŠµë‹ˆë‹¤.")
                st.session_state.auto_playing = False
                st.session_state.waiting_for_decision = True
                st.rerun()

    scroll_to_bottom()
    
    speaker_name = "ChatGPT" if next_speaker == "left" else "Claude"
    avatar_icon = "ğŸ”¥" if next_speaker == "left" else "â„ï¸"
    search_evidence = None

    with st.status(f"ğŸ¤” {speaker_name}ê°€ ê³µê²©ì„ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤...", expanded=True) as status:
        st.write("ì‘ì „ êµ¬ìƒ ë° ê²€ìƒ‰ í•„ìš”ì„± íŒë‹¨ ì¤‘...")
        
        keys = {'openai': openai_key, 'anthropic': anthropic_key, 'google': google_key}
        context_str = st.session_state.messages[-1]['content']
        search_query_res = get_search_query_if_needed(next_speaker, context_str, keys)
        
        if "SEARCH:" in search_query_res:
            query = search_query_res.replace("SEARCH:", "").strip()
            st.write(f"ğŸ” ì›¹ ê²€ìƒ‰ ì‹œë„: '{query}'")
            search_evidence = search_web(query)
            if search_evidence:
                st.write("âœ… ì¦ê±° í™•ë³´ ì™„ë£Œ")
            else:
                st.write("âŒ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
        else:
            st.write("âš¡ ìì²´ ë…¼ë¦¬ë¡œ ëŒ€ì‘í•©ë‹ˆë‹¤.")
            
        status.update(label=f"ğŸ‘Š {speaker_name} ë°œì–¸ ì¤€ë¹„ ì™„ë£Œ!", state="complete", expanded=False)

    with st.chat_message("assistant", avatar=avatar_icon):
        response_placeholder = st.empty()
        response_text = ""
        
        system_prompt = get_system_prompt(next_speaker, turn_count=st.session_state.turn_count, search_evidence=search_evidence)
        api_messages = build_api_messages(next_speaker, st.session_state.messages)
        
        try:
            if next_speaker == "left":
                client = OpenAI(api_key=openai_key)
                stream = client.chat.completions.create(
                    model="gpt-5.1", 
                    messages=[{"role": "system", "content": system_prompt}] + api_messages,
                    stream=True
                )
                for chunk in stream:
                    content = chunk.choices[0].delta.content
                    if content:
                        response_text += content
                        response_placeholder.markdown(f"**ChatGPT (ë¶ˆë„ì €):**\n\n{response_text}â–Œ")
                response_placeholder.markdown(f"**ChatGPT (ë¶ˆë„ì €):**\n\n{response_text}")

            elif next_speaker == "right":
                client = Anthropic(api_key=anthropic_key)
                with client.messages.stream(
                    max_tokens=8192,
                    messages=api_messages,
                    model="claude-sonnet-4-5-20250929",
                    system=system_prompt
                ) as stream:
                    for text in stream.text_stream:
                        response_text += text
                        response_placeholder.markdown(f"**Claude (ë…ì„¤ê°€):**\n\n{response_text}â–Œ")
                response_placeholder.markdown(f"**Claude (ë…ì„¤ê°€):**\n\n{response_text}")
            
            st.session_state.messages.append({"role": next_speaker, "content": response_text})
            st.session_state.turn_count += 1
            
            scroll_to_bottom()
            time.sleep(0.5)
            st.rerun()

        except Exception as e:
            st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
            st.session_state.auto_playing = False

# [ìƒíƒœ E] íŒê²° ìë™ ì§‘í–‰
elif st.session_state["waiting_for_decision"]:
    
    st.markdown("---")
    
    with st.chat_message("assistant", avatar="âš–ï¸"):
        st.markdown("### âš–ï¸ ìµœì¢… íŒê²° ì§‘í–‰")
        st.caption("ì œë¯¸ë‚˜ì´ ì¬íŒê´€ì´ 'ì‚¬ìš©ìì˜ ìµœì´ˆ ì§ˆë¬¸'ì— ëŒ€í•œ ìµœê³ ì˜ ë‹µì„ ë‚´ë¦½ë‹ˆë‹¤...")
        
        with st.spinner("íŒê²°ë¬¸ì„ ì‘ì„± ì¤‘ì…ë‹ˆë‹¤..."):
            scroll_to_bottom()
            
            context_str = ""
            role_map_k = {"left": "ChatGPT(ì „ëµê°€)", "right": "Claude(ë…ì„¤ê°€)", "user": "ì‚¬ìš©ì", "chief": "íŒì‚¬"}
            for m in st.session_state.messages:
                r = m["role"]
                if r in ["user", "left", "right"]:
                    context_str += f"[{role_map_k.get(r, r)}] : {m['content']}\n"
            
            system_prompt = get_system_prompt("chief", context_history=context_str)
            
            try:
                genai.configure(api_key=google_key)
                model = genai.GenerativeModel('gemini-2.5-pro')
                
                response_placeholder = st.empty()
                response_text = ""
                
                res = model.generate_content(system_prompt, stream=True)
                for chunk in res:
                    if chunk.text:
                        response_text += chunk.text
                        response_placeholder.markdown(f"**Gemini (íŒê²°):**\n\n{response_text}â–Œ")
                        time.sleep(0.005)
                        
                response_placeholder.markdown(f"**Gemini (íŒê²°):**\n\n{response_text}")
                
                st.session_state.messages.append({"role": "chief", "content": response_text})
                
                st.session_state.waiting_for_decision = False
                st.session_state.finished = True
                scroll_to_bottom()
                st.rerun()
                
            except Exception as e:
                 st.error(f"íŒê²° ì¤‘ ì˜¤ë¥˜: {e}")
                 if st.button("ğŸ”„ íŒê²° ë‹¤ì‹œ ì‹œë„"):
                     st.rerun()
